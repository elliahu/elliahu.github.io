[{"content":"My computer graphics journey I’ve always enjoyed playing video games, but not quite like everybody else. While most people are busy saving the world or fighting off enemies, I’m sitting there wondering, how do they make this look so good? Like, how do they turn a bunch of code into moss so realistic it makes you want to touch it? These questions didn’t just cross my mind—they took over my life.\nNow, as a software engineer, I’ve made it my mission to understand how computer graphics actually work. Shaders, rendering pipelines, real-time lighting—it’s like a giant puzzle, and I can’t resist taking it apart to see how it fits together. Honestly, building these systems is just as fun (if not more) than watching the final visuals on the screen.\nI’ll never forget the time I played Horizon Forbidden West on the PS5. While everyone else was raving about the story and gameplay, I was staring at a patch of moss. One patch of moss. For an hour. I mean, the texture, the lighting, the tiny imperfections—chef’s kiss. That moss made me realize just how much I love the mix of art and engineering behind computer graphics.\nIt’s not just about games, either. From virtual reality to scientific simulations, I’m fascinated by how graphics shape our digital worlds. Whether I’m geeking out over shaders or brainstorming new ways to render something cool, I’m all in. It’s not just work; it’s what keeps me curious—and occasionally makes me weirdly emotional about moss.\n","permalink":"http://localhost:1313/about/","summary":"\u003ch2 id=\"my-computer-graphics-journey\"\u003eMy computer graphics journey\u003c/h2\u003e\n\u003cp\u003eI’ve always enjoyed playing video games, but not quite like everybody else. While most people are busy saving the world or fighting off enemies, I’m sitting there wondering, how do they make this look so good? Like, how do they turn a bunch of code into moss so realistic it makes you want to touch it? These questions didn’t just cross my mind—they took over my life.\u003c/p\u003e","title":"About me"},{"content":"Custom real-time physically-based graphics engine using c++23 and Vulkan - the next generation graphics API.\nAbout this project I\u0026rsquo;ve always enjoyed playing video games, but not quite like everyone else. While most people are immersed in the gameplay, I’ve always been curious about what’s happening under the hood. How do these games keep looking better and better? How is it even possible to render such detailed worlds on everyday hardware? These questions have fascinated me for as long as I can remember.\nOnce, while playing Horizon Forbidden West on the PS5, I spent over an hour just staring at a patch of moss—completely captivated by how realistic it looked. That’s who I am: someone who’s endlessly intrigued by the technology powering the visuals.\nMy first real hands-on experience with computer graphics was during university. While the professor wasn’t exactly the most approachable person, I thoroughly enjoyed the lectures. What I love most about computer graphics is how theory and practice come together to create something tangible—something you can see and interact with.\nI started my graphics programming journey with OpenGL, learning the basics and building a strong foundation. At some point, for no particular reason other than that it sounded cool, I decided to dive into Vulkan. Many years (and countless challenges) later, here I am, working on a Vulkan-based graphics engine. It’s been a long road filled with sweat, tears, and plenty of late nights, but I’m proud of what I’ve accomplished so far.\nThe project is still a work in progress—there are parts of the code that need serious rewrites—but every day it gets better. And to me, that’s the exciting part: the process of creating, learning, and improving.\nYou can find the source code and more information in the official repository.\nScreenshots Here you can screenshots from some of my rendering endeavors using the Hammock. ","permalink":"http://localhost:1313/projects/hammock/","summary":"\u003cp\u003eCustom real-time physically-based graphics engine using c++23 and Vulkan - the next generation graphics API.\u003c/p\u003e\n\u003ch2 id=\"about-this-project\"\u003eAbout this project\u003c/h2\u003e\n\u003cp\u003eI\u0026rsquo;ve always enjoyed playing video games, but not quite like everyone else. While most people are immersed in the gameplay, I’ve always been curious about what’s happening under the hood. How do these games keep looking better and better? How is it even possible to render such detailed worlds on everyday hardware? These questions have fascinated me for as long as I can remember.\u003c/p\u003e","title":"Hammock - Vulkan graphics engine"},{"content":"About this project In graphics engines and renderers, window management and event handling is often a necessary but tedious task. Most developers choose to abstract this functionality using libraries like GLFW, SDL, or similar tools. While these libraries are robust and feature-rich, they tend to be heavyweight and require installation via NuGet, vcpkg, or manual downloads. This can impact the portability of projects that rely on them.\nAs a researcher and graphics programming enthusiast, my needs are simpler. I primarily need a window for the rendering surface and basic input handling—just enough to close the window with the Esc key or enable basic camera movement. For such straightforward requirements, using a large library often feels like overkill. Don’t get me wrong—SDL2 is excellent, and GLFW is truly amazing. But for smaller projects, their size and complexity can be unnecessary.\nWhen I looked for lightweight, single-header alternatives, I was surprised to find a lack of options tailored to Vulkan. The OpenGL ecosystem has plenty of solutions, but Vulkan seems to have been overlooked in this area. That’s why I decided to create my own solution.\nWhat started as a utility extracted from my renderer has evolved into a portable, single-header window library designed specifically for Vulkan. It’s simple, lightweight, and focuses on exactly what’s needed—nothing more, nothing less.\nThis project aims to make creation of a window with a Vulkan surface and basic event handling as simple and portable as possible. If you just need a window with Vulkan surface and basic event handling, this is the tool you need. Library is header-only single file and there is no need for implementation files. Just drop it into you project.\nSimple API The window API was made so it is as simple as possible. Open a window and create a VkSurface in just two lines:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #define SURFER_PLATFORM_X11 #include \u0026#34;VulkanSurfer.h\u0026#34; // Create a window Surfer::Window * window = Surfer::Window::createWindow(\u0026#34;Example window\u0026#34;, instance, 800, 600 , 100, 100 ); // Get the surface VkSurfaceKHR surface = window-\u0026gt;getSurface(); // Draw while (!window-\u0026gt;shouldClose()) { // poll for events window-\u0026gt;pollEvents(); // do your rendering } // Don\u0026#39;t forget to destroy the window Surfer::Window::destroyWindow(window); See the full example here.\nCallback-based event handling Event handling is done using simple callback system.\n1 2 3 window-\u0026gt;registerKeyPressCallback([](Surfer::KeyCode key) { std::cout \u0026lt;\u0026lt; \u0026#34;Key pressed \u0026#34; \u0026lt;\u0026lt; static_cast\u0026lt;unsigned int\u0026gt;(key) \u0026lt;\u0026lt; std::endl; }); You can find the source code in the official repository.\n","permalink":"http://localhost:1313/projects/surfer/","summary":"\u003ch2 id=\"about-this-project\"\u003eAbout this project\u003c/h2\u003e\n\u003cp\u003eIn graphics engines and renderers, window management and event handling is often a necessary but tedious task. Most developers choose to abstract this functionality using libraries like GLFW, SDL, or similar tools. While these libraries are robust and feature-rich, they tend to be heavyweight and require installation via NuGet, vcpkg, or manual downloads. This can impact the portability of projects that rely on them.\u003c/p\u003e\n\u003cp\u003eAs a researcher and graphics programming enthusiast, my needs are simpler. I primarily need a window for the rendering surface and basic input handling—just enough to close the window with the Esc key or enable basic camera movement. For such straightforward requirements, using a large library often feels like overkill. Don’t get me wrong—SDL2 is excellent, and GLFW is truly amazing. But for smaller projects, their size and complexity can be unnecessary.\u003c/p\u003e","title":"VulkanSurfer - minimal window library for Vulkan"},{"content":"Introduction In this article, we explore the VK_KHR_dynamic_rendering extension, which eliminates the need for VkRenderPass and VkFramebuffer objects. By using this extension, rendering attachments (commonly referred to as render targets in other APIs) can be directly referenced before rendering begins.\nHow It Works Before Dynamic Rendering Previously, Vulkan required you to create a render pass, specifying the types of attachments to be used. Subpass dependencies could also be defined to handle attachment transitions after the render pass finishes. For example, a subpass could transition a color attachment from VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL to VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL, allowing the attachment to be used as input in another pass.\nAdditionally, a framebuffer object representing the actual attachment images (via their views) had to be created. This framebuffer was statically linked to a specific render pass. For a single logical rendering pass, you needed both a VkRenderPass and a VkFramebuffer, which had to be properly disposed of when no longer needed. Here’s how this process looked in code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 // Use subpass dependencies for attachment layout transitions std::array\u0026lt;VkSubpassDependency, 2\u0026gt; dependencies{}; // Define the dependencies... // Create render pass VkRenderPassCreateInfo renderPassInfo = {}; renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO; renderPassInfo.pAttachments = attachmentDescriptions.data(); renderPassInfo.attachmentCount = static_cast\u0026lt;uint32_t\u0026gt;(attachmentDescriptions.size()); renderPassInfo.subpassCount = 1; renderPassInfo.pSubpasses = \u0026amp;subpass; renderPassInfo.dependencyCount = 2; renderPassInfo.pDependencies = dependencies.data(); if (vkCreateRenderPass(device.device(), \u0026amp;renderPassInfo, nullptr, \u0026amp;renderPass) != VK_SUCCESS) { throw std::runtime_error(\u0026#34;Failed to create render pass\u0026#34;); } // Create the framebuffer VkFramebufferCreateInfo framebufferInfo = {}; framebufferInfo.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO; framebufferInfo.renderPass = renderPass; // Requires render pass framebufferInfo.pAttachments = attachmentViews.data(); framebufferInfo.attachmentCount = static_cast\u0026lt;uint32_t\u0026gt;(attachmentViews.size()); framebufferInfo.width = width; framebufferInfo.height = height; framebufferInfo.layers = maxLayers; if (vkCreateFramebuffer(device.device(), \u0026amp;framebufferInfo, nullptr, \u0026amp;framebuffer) != VK_SUCCESS) { throw std::runtime_error(\u0026#34;Failed to create framebuffer\u0026#34;); } // Begin the render pass VkRenderPassBeginInfo renderPassBeginInfo = Init::renderPassBeginInfo(); renderPassBeginInfo.renderPass = renderPass; renderPassBeginInfo.framebuffer = framebuffer; renderPassBeginInfo.renderArea.extent.width = width; renderPassBeginInfo.renderArea.extent.height = height; renderPassBeginInfo.clearValueCount = 3; renderPassBeginInfo.pClearValues = clearValues.data(); vkCmdBeginRenderPass(drawCmdBuffer, \u0026amp;renderPassBeginInfo, VK_SUBPASS_CONTENTS_INLINE); // Draw the scene vkCmdEndRenderPass(drawCmdBuffer); Note on Graphics Pipelines When creating a graphics pipeline, the VkGraphicsPipelineCreateInfo structure required a valid render pass object. As a result, pipelines were directly tied to specific render passes.\nWith Dynamic Rendering Dynamic rendering eliminates the need for both render pass and framebuffer objects. Instead, attachments are described using the VkRenderingAttachmentInfoKHR structure:\n1 2 3 4 5 6 7 VkRenderingAttachmentInfoKHR attachmentInfo{}; attachmentInfo.sType = VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO_KHR; attachmentInfo.imageView = colorAttachment.view; attachmentInfo.imageLayout = colorAttachment.layout; attachmentInfo.loadOp = access.loadOp; attachmentInfo.storeOp = access.storeOp; attachmentInfo.clearValue = {...}; Rendering begins with the VkRenderingInfoKHR structure and the vkCmdBeginRenderingKHR command:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 VkRenderingInfoKHR renderingInfo{VK_STRUCTURE_TYPE_RENDERING_INFO_KHR}; renderingInfo.renderArea = {...}; renderingInfo.layerCount = 1; renderingInfo.colorAttachmentCount = colorAttachments.size(); renderingInfo.pColorAttachments = colorAttachments.data(); renderingInfo.pDepthAttachment = \u0026amp;depthAttachment; renderingInfo.pStencilAttachment = VK_NULL_HANDLE; // Start dynamic rendering vkCmdBeginRenderingKHR(renderContext.getCurrentCommandBuffer(), \u0026amp;renderingInfo); // Draw the scene // End rendering vkCmdEndRenderingKHR(renderContext.getCurrentCommandBuffer()); Looks simpler? It is.\nGraphics Pipelines Previously, pipeline objects required a pointer to a valid render pass. With dynamic rendering, you can simply set the renderPass field in VkGraphicsPipelineCreateInfo to VK_NULL_HANDLE. To support dynamic rendering, attach a VkPipelineRenderingCreateInfoKHR structure to the pNext field of VkGraphicsPipelineCreateInfo:\n1 2 3 4 5 6 7 8 9 10 11 VkPipelineRenderingCreateInfoKHR pipelineCreate{VK_STRUCTURE_TYPE_PIPELINE_RENDERING_CREATE_INFO_KHR}; pipelineCreate.pNext = VK_NULL_HANDLE; pipelineCreate.colorAttachmentCount = colorAttachmentFormats.size(); pipelineCreate.pColorAttachmentFormats = colorAttachmentFormats.data(); pipelineCreate.depthAttachmentFormat = depthFormat; pipelineCreate.stencilAttachmentFormat = depthFormat; // Use pNext to reference the pipelineCreate structure VkGraphicsPipelineCreateInfo graphicsCreate{VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO}; graphicsCreate.pNext = \u0026amp;pipelineCreate; graphicsCreate.renderPass = VK_NULL_HANDLE; // Now optional And that’s it.\nBenefits Why use dynamic rendering? Here are some key advantages:\nSimplified API: Render passes add hidden complexity by automatically transitioning images, which can be hard to trace. Dynamic rendering exposes transitions directly, offering more control to developers.\nEase of Render Graph Implementation: Building a per-frame render graph (or frame graph) is challenging with static render passes and framebuffers. Dynamic rendering eliminates the need for object pooling and pass matching, reducing the workload.\nImproved Resource Management: Managing VkFramebuffer and VkRenderPass objects is cumbersome, especially when render target lifespans are unpredictable. Dynamic rendering simplifies this process and reduces CPU overhead.\nFlexibility in Pipeline Design: With dynamic rendering, pipelines are no longer tied to specific render passes. This decoupling allows greater flexibility when designing and reusing pipelines across different rendering setups.\nReduced Boilerplate Code: By removing the need for VkRenderPass and VkFramebuffer objects, dynamic rendering significantly reduces the amount of boilerplate code, making Vulkan applications easier to write and maintain.\nSimplified Attachment Management: Managing attachments is more intuitive with dynamic rendering. You can directly specify the attachments during rendering without needing to predefine them in a render pass.\nPerformance Considerations On desktop GPUs, performance differences between dynamic rendering and traditional render passes are negligible. While desktop GPUs can occasionally benefit from additional information provided by render passes, this is mostly relevant for mobile GPUs, where the driver optimizations are more pronounced.\nDynamic rendering is ideal when you don’t need the specific advantages of traditional render passes, providing a low-overhead, streamlined API for most applications.\nAdditional Reading Vulkan Do\u0026rsquo;s and Don\u0026rsquo;ts RDNA Performance Guide ","permalink":"http://localhost:1313/posts/vulkan-dynamic-rendering/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this article, we explore the \u003ccode\u003eVK_KHR_dynamic_rendering\u003c/code\u003e extension, which eliminates the need for \u003ccode\u003eVkRenderPass\u003c/code\u003e and \u003ccode\u003eVkFramebuffer\u003c/code\u003e objects. By using this extension, rendering attachments (commonly referred to as render targets in other APIs) can be directly referenced before rendering begins.\u003c/p\u003e\n\u003ch2 id=\"how-it-works\"\u003eHow It Works\u003c/h2\u003e\n\u003ch3 id=\"before-dynamic-rendering\"\u003eBefore Dynamic Rendering\u003c/h3\u003e\n\u003cp\u003ePreviously, Vulkan required you to create a render pass, specifying the types of attachments to be used. Subpass dependencies could also be defined to handle attachment transitions after the render pass finishes. For example, a subpass could transition a color attachment from \u003ccode\u003eVK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL\u003c/code\u003e to \u003ccode\u003eVK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL\u003c/code\u003e, allowing the attachment to be used as input in another pass.\u003c/p\u003e","title":"Dynamic rendering in Vulkan 1.3"}]